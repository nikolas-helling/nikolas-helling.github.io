<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="XFUI4-qITA-adI-KHb247EIycGe29jkTMZelrcYYVc4"> <meta name="msvalidate.01" content="45781F344C0DA9E42211C13CCD701B43"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Master Thesis Research | Nikolas Helling </title> <meta name="author" content="Nikolas Helling"> <meta name="description" content="Human behavior prediction for human-robot collaboration, using Bayesian inference and low-level human motion generation"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/pers_website_logo.jpg?a5fd628cc23908530730ebfa2d4089ed"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://nikolas-helling.github.io/projects/1_project/"> <script src="/assets/js/theme.js?bc98222b904c9daed12bdba53b2b5c28"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Nikolas</span> <span class="font-weight-bold">Helling</span> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About Me </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Master Thesis Research</h1> <p class="post-description">Human behavior prediction for human-robot collaboration, using Bayesian inference and low-level human motion generation</p> </header> <article> <p>During my master’s thesis at <a href="https://merlin.deib.polimi.it/" rel="external nofollow noopener" target="_blank">MERLIN Lab</a>, I carried out robotics research under the supervision of Prof. Paolo Rocco. My research focused on human behavior prediction for collaborative robotics applications in industrial assembly. This research addresses a critical need in the field of collaborative robotics, where improving human-robot interaction is essential for advancing efficiency, safety, and adaptability in shared workspaces. Traditional collaboration approaches often struggle to integrate predicted human intentions in dynamic environments, limiting their advantages in real-world industrial settings. By bridging this gap, my work aimed to prove the enhancements obtained by applying short-term human intention prediction in terms of collaboration fluency and robot intuitiveness.</p> <p>I developed a “Robust Bayesian Goal Reaching Inference Engine for Intent Prediction in Human-Robot Collaboration”, which was validated using a collaborative dual-arm robot (ABB’s YuMi) and external participants. The model accurately predicts the objects grasped by a human inside a collaborative workspace, combining upper body tracking, limb motion generation, and Bayesian target prediction. The experimental campaign demonstrated significant collaboration improvements, including a 30% reduction in cycle time for shared assembly tasks, more natural and intelligent human-robot interactions, and increased robustness compared to prior works in the literature <a class="citation" href="#paperICRA2023">(Huang et al., 2023; Casalino et al., 2018; Zanchettin &amp; Rocco, 2017)</a>.</p> <div class="row align-items-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/proj1/setup-480.webp 480w,/assets/img/proj1/setup-800.webp 800w,/assets/img/proj1/setup-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/proj1/setup.gif" class="img-fluid rounded z-depth-1" width="70%" height="70%" style="display: flex; justify-content: center; align-items: center; margin: auto;" title="Application setup" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Working setup of the prediction model. </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/proj1/use_case_screenshot-480.webp 480w,/assets/img/proj1/use_case_screenshot-800.webp 800w,/assets/img/proj1/use_case_screenshot-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/proj1/use_case_screenshot.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Shared human-robot assembly experiment. </div> </div> </div> <p>The proposed model is built within a Bayesian inference framework, aiming for a generalized approach that does not rely on any specific training and is computationally efficient. First, a hand motion generation problem is solved, whose output then serves as input to the Bayesian prediction layer. The model aims to predict the most likely reaching target for a user by inferring from the last available 3D arm data (positions and tangents). This allows for automatic replanning of robot actions during shared human-robot tasks, accounting for the inherent uncertainty of the human and increasing the overall safety of operation.</p> <p>The captured human arm’s movement is spatially discretized, with updates occurring only during significant motion, helping to focus on reaching intentions and ignore stationary phases. The path generation model employs a minimum curvature approach, optimizing hand motion by minimizing the overall path curvature, subject to boundary conditions like current position and tangent. Solving a convex quadratic optimization results in smooth polynomial paths for each goal object, which are then used as predictive information in the inference step.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/proj1/traj_scheme-480.webp 480w,/assets/img/proj1/traj_scheme-800.webp 800w,/assets/img/proj1/traj_scheme-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/proj1/traj_scheme.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Path generation example. </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/proj1/tangents_scheme-480.webp 480w,/assets/img/proj1/tangents_scheme-800.webp 800w,/assets/img/proj1/tangents_scheme-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/proj1/tangents_scheme.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Human arm feature extraction. </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/proj1/u_goal-480.webp 480w,/assets/img/proj1/u_goal-800.webp 800w,/assets/img/proj1/u_goal-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/proj1/u_goal.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Robustness to prediction uncertainty. </div> </div> </div> <p>The underlying probabilistic model uses Bayesian inference to update the posterior probability distribution over a set of suitable goals, based on measured and predicted human features. The problem is framed as a classification task, aiming to identify the most likely goal by updating the probability distribution recursively using a Bayes classifier. The probability update is divided into prediction and measurement steps. Markov’s assumption simplifies the model’s structure, ensuring that the distribution depends only on the latest measurements, implicitly favoring more reactive predictions.</p> <p>The prior distribution is computed using a transition model for intentions, which defines the probability of the operator switching goals between samples. In the measurement step, the posterior distribution is updated using new captured data and predicted paths. The final predicted goal is the one with the highest posterior probability, provided it exceeds a certain threshold. This pipeline allows for efficient short-term motion prediction with reduced computational complexity. Given the captured features \(\mathbf{\hat{X}}\), the prior and posterior distributions are computed over the set of known goals \(\mathbf{G}\) with a procedure as the following:</p> \[P^{prior}_{k+1}(\mathbf{g}) = \mathbb{P}\left(\mathbf{g}^{k+1} \mid \mathbf{\hat{X}}_{k}\right)=(\cdots)= \sum_{\mathbf{g}^k \in \mathbf{G}} P^{post}_{k}(\mathbf{g})\mathbb{P}\left(\mathbf{g}^{k+1} \mid \mathbf{g}^k\right),\] \[\label{eq:cauchy-schwarz} P^{post}_{k+1}(\mathbf{g}) = \mathbb{P}\left(\mathbf{g}^{k+1} \mid \mathbf{\hat{X}}_{k}, \mathbf{\hat{X}}_{k+1}\right) = (\cdots) = \eta_{k+1}L_{k+1}(\mathbf{g})P^{prior}_{k+1}(\mathbf{g})\] <p>The likelihood function evaluates how well each potential goal aligns with current and predicted human movements. Key measures include the angle between predicted and measured hand tangents , the distance between the hand and each goal, and the alignment of the shoulder’s motion with the goal direction for certain movements. These measures are combined into a likelihood function modeled as a mixture of normal distributions. Weights are dynamically adjusted to favor angular measures for distant goals and distance measures for nearby ones, increasing robustness in case of aligned goals. Moreover, only goals within the hand’s general motion direction are considered, while entropy is used to handle uncertainty, increasing the probability of an unknown goals when none of the current goals seem likely. This approach ensures smoother and more accurate predictions while addressing variability and ambiguous cases.</p> <div class="row align-items-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/proj1/post_dist-480.webp 480w,/assets/img/proj1/post_dist-800.webp 800w,/assets/img/proj1/post_dist-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/proj1/post_dist.jpg" class="img-fluid rounded z-depth-1" width="95%" height="95%" style="display: flex; justify-content: center; align-items: center; margin: auto;" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Example of prediction model's output. </div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/proj1/cycle_time-480.webp 480w,/assets/img/proj1/cycle_time-800.webp 800w,/assets/img/proj1/cycle_time-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/proj1/cycle_time.png" class="img-fluid rounded z-depth-1" width="70%" height="70%" style="display: flex; justify-content: center; align-items: center; margin: auto;" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption"> Assembly cycle time improvements. </div> </div> </div> <p>The model’s prediction performance was tested on a comprehensive dataset of recorded human paths, achieving high accuracy (95%) and early goal prediction, with confirmation happening at only around 1/4 of the full path. Incorporating shoulder information improved prediction speed (+9%) and reduced variability (−13%), enabling more robust predictions. The model also successfully identified unknown goals in 89% of tests, demonstrating its adaptability.</p> <p>In a collaborative robotics use case, the predictive model significantly reduced assembly cycle times (−30%) compared to non-predictive setups. Participants in experimental trials also noted improved task fluency and robot intuitiveness when the model was used. These results validate the model’s robustness and effectiveness for real-world human-robot collaboration, enhancing efficiency and interaction quality. This work was a great opportunity to apply HRI research and appreciate the potential of novel interactions between humans and robots, paving the way for future works that develop adaptive deep learning algorithms to enable seamless HRI in more complex and unstructured environments.</p> <div class="row align-items-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <video src="/assets/video/coll_assembly_slim.mp4" class="img-fluid rounded z-depth-1" width="60%" height="60%" style="display: flex; justify-content: center; align-items: center; margin: auto;" controls=""></video> </figure> <div class="caption"> Full collaborative assembly example using the prediction model. </div> </div> </div> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="paperICRA2023" class="col-sm-8"> <div class="title">Hierarchical Intention Tracking for Robust Human-Robot Collaboration in Industrial Assembly Tasks</div> <div class="author"> Zhe Huang, Ye-Ji Mun, Xiang Li, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Yiqing Xie, Ninghan Zhong, Weihang Liang, Junyi Geng, Tan Chen, Katherine Driggs-Campbell' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>In 2023 IEEE International Conference on Robotics and Automation (ICRA)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="casalino2018operator" class="col-sm-8"> <div class="title">Operator awareness in human–robot collaboration through wearable vibrotactile feedback</div> <div class="author"> Andrea Casalino, Costanza Messeri, Maria Pozzi, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Andrea Maria Zanchettin, Paolo Rocco, Domenico Prattichizzo' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>IEEE Robotics and Automation Letters</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Zanchettin2017" class="col-sm-8"> <div class="title">Probabilistic inference of human arm reaching target for effective human-robot collaboration</div> <div class="author"> Andrea Maria Zanchettin, and Paolo Rocco </div> <div class="periodical"> <em>In 2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Nikolas Helling. Powered by Jekyll with al-folio theme and hosted on GitHub Pages. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script>for(var wechatModal=document.getElementById("WeChatMod"),wechatBtn=document.querySelectorAll('[id="WeChatBtn"]'),i=0;i<wechatBtn.length;i++)wechatBtn[i].onclick=function(){wechatModal.style.display="block"};window.onclick=function(t){t.target==wechatModal&&(wechatModal.style.display="none")};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>